\subsubsection{Filter Methods}
\label{sec:methods.flat.filter}

% Author: Silvana

As the name suggests, filter methods try to filter out relevant features from
non-relevant ones. This is done by considering only the data set itself, while
the properties of the classifier used afterward are ignored.
 
This makes filter methods computationally efficient and somewhat flexible, 
as any classifier can be used on the filtered features.  

But this independence has also its drawbacks. As the characteristics of the 
specific classifiers are not considered, it is not known which one works 
best with the selected subset. Thus the selected subset does not guarantee optimal 
performance of the classifier.

Because features are normally evaluated independent of each other, filter methods often
fail to remove redundant features. Some methods try to overcome this problem by 
considering possible correlations between features.

Filter methods perform two phases sequentially: First, they rank the features according 
to a certain metric. The features with the highest rankings are then chosen to train the
classifier. 

The following chapters will present some popular filter methods and the metrics they use
for ranking features.

\input{chapters/methods/flat/filter/fisher_score}
\input{chapters/methods/flat/filter/mutual_information}
\input{chapters/methods/flat/filter/relief}