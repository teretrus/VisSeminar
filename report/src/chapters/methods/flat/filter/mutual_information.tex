\paragraph{Mutual information based}
\label{par:methods.flat.filter.mutual_information}

% Author: Flo - Silvana haut auch was rein
  
Mutual information  = how much one variable tells us about another- No mutual information measn they are independent, high mutual information means they are dependent on each other - in other words, quantifies how dependent two variables are

Different method based on this idea like min redundancy max relevance, information gain

mRmr = combine measures for redundancy and relevance, select features with high relevance and minimize redundancy.

infogain = feature given and a corresponding class distribution - measure amount of information regarding class prediction when this feature is given - select features which contriburte high information gein